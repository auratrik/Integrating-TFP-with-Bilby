{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "%matplotlib notebook\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bilby\n",
    "from bilby.core.prior import Uniform\n",
    "from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters, generate_all_bbh_parameters\n",
    "\n",
    "from gwpy.timeseries import TimeSeries\n",
    "\n",
    "import lal\n",
    "import lalsimulation as lalsim\n",
    "\n",
    "from bilby.core import utils\n",
    "from bilby.core.utils import logger\n",
    "from bilby.gw.conversion import bilby_to_lalsimulation_spins\n",
    "from bilby.gw.utils import (lalsim_GetApproximantFromString,\n",
    "                    lalsim_SimInspiralFD,\n",
    "                    lalsim_SimInspiralChooseFDWaveform,\n",
    "                    lalsim_SimInspiralWaveformParamsInsertTidalLambda1,\n",
    "                    lalsim_SimInspiralWaveformParamsInsertTidalLambda2,\n",
    "                    lalsim_SimInspiralChooseFDWaveformSequence,\n",
    "                    convert_args_list_to_float, \n",
    "                    _get_lalsim_approximant)\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numbers\n",
    "from itertools import chain, combinations\n",
    "from itertools import combinations_with_replacement as combinations_w_r\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.interpolate import BSpline\n",
    "from scipy.special import comb\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils.deprecation import deprecated\n",
    "from sklearn.utils.validation import check_is_fitted, FLOAT_DTYPES, _check_sample_weight\n",
    "from sklearn.utils.validation import _check_feature_names_in\n",
    "from sklearn.utils.stats import _weighted_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy Polynomial Transform Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(self, X):\n",
    "        \"\"\"Transform data to polynomial features.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            The data to transform, row by row.\n",
    "            Prefer CSR over CSC for sparse input (for speed), but CSC is\n",
    "            required if the degree is 4 or higher. If the degree is less than\n",
    "            4 and the input format is CSC, it will be converted to CSR, have\n",
    "            its polynomial features generated, then converted back to CSC.\n",
    "            If the degree is 2 or 3, the method described in \"Leveraging\n",
    "            Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices\n",
    "            Using K-Simplex Numbers\" by Andrew Nystrom and John Hughes is\n",
    "            used, which is much faster than the method used on CSC input. For\n",
    "            this reason, a CSC input will be converted to CSR, and the output\n",
    "            will be converted back to CSC prior to being returned, hence the\n",
    "            preference of CSR.\n",
    "        Returns\n",
    "        -------\n",
    "        XP : {ndarray, sparse matrix} of shape (n_samples, NP)\n",
    "            The matrix of features, where `NP` is the number of polynomial\n",
    "            features generated from the combination of inputs. If a sparse\n",
    "            matrix is provided, it will be converted into a sparse\n",
    "            `csr_matrix`.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        X = self._validate_data(\n",
    "            X, order=\"F\", dtype=FLOAT_DTYPES, reset=False, accept_sparse=(\"csr\", \"csc\")\n",
    "        )\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if sparse.isspmatrix_csr(X):\n",
    "            if self._max_degree > 3:\n",
    "                return self.transform(X.tocsc()).tocsr()\n",
    "            to_stack = []\n",
    "            if self.include_bias:\n",
    "                to_stack.append(\n",
    "                    sparse.csc_matrix(np.ones(shape=(n_samples, 1), dtype=X.dtype))\n",
    "                )\n",
    "            if self._min_degree <= 1 and self._max_degree > 0:\n",
    "                to_stack.append(X)\n",
    "            for deg in range(max(2, self._min_degree), self._max_degree + 1):\n",
    "                Xp_next = _csr_polynomial_expansion(\n",
    "                    X.data, X.indices, X.indptr, X.shape[1], self.interaction_only, deg\n",
    "                )\n",
    "                if Xp_next is None:\n",
    "                    break\n",
    "                to_stack.append(Xp_next)\n",
    "            if len(to_stack) == 0:\n",
    "                # edge case: deal with empty matrix\n",
    "                XP = sparse.csr_matrix((n_samples, 0), dtype=X.dtype)\n",
    "            else:\n",
    "                XP = sparse.hstack(to_stack, format=\"csr\")\n",
    "        elif sparse.isspmatrix_csc(X) and self._max_degree < 4:\n",
    "            return self.transform(X.tocsr()).tocsc()\n",
    "        elif sparse.isspmatrix(X):\n",
    "            combinations = self._combinations(\n",
    "                n_features=n_features,\n",
    "                min_degree=self._min_degree,\n",
    "                max_degree=self._max_degree,\n",
    "                interaction_only=self.interaction_only,\n",
    "                include_bias=self.include_bias,\n",
    "            )\n",
    "            columns = []\n",
    "            for combi in combinations:\n",
    "                if combi:\n",
    "                    out_col = 1\n",
    "                    for col_idx in combi:\n",
    "                        out_col = X[:, col_idx].multiply(out_col)\n",
    "                    columns.append(out_col)\n",
    "                else:\n",
    "                    bias = sparse.csc_matrix(np.ones((X.shape[0], 1)))\n",
    "                    columns.append(bias)\n",
    "            XP = sparse.hstack(columns, dtype=X.dtype).tocsc()\n",
    "        else:\n",
    "            # Do as if _min_degree = 0 and cut down array after the\n",
    "            # computation, i.e. use _n_out_full instead of n_output_features_.\n",
    "            XP = np.empty(\n",
    "                shape=(n_samples, self._n_out_full), dtype=X.dtype, order=self.order\n",
    "            )\n",
    "\n",
    "            # What follows is a faster implementation of:\n",
    "            # for i, comb in enumerate(combinations):\n",
    "            #     XP[:, i] = X[:, comb].prod(1)\n",
    "            # This implementation uses two optimisations.\n",
    "            # First one is broadcasting,\n",
    "            # multiply ([X1, ..., Xn], X1) -> [X1 X1, ..., Xn X1]\n",
    "            # multiply ([X2, ..., Xn], X2) -> [X2 X2, ..., Xn X2]\n",
    "            # ...\n",
    "            # multiply ([X[:, start:end], X[:, start]) -> ...\n",
    "            # Second optimisation happens for degrees >= 3.\n",
    "            # Xi^3 is computed reusing previous computation:\n",
    "            # Xi^3 = Xi^2 * Xi.\n",
    "\n",
    "            # degree 0 term\n",
    "            if self.include_bias:\n",
    "                XP[:, 0] = 1\n",
    "                current_col = 1\n",
    "            else:\n",
    "                current_col = 0\n",
    "\n",
    "            if self._max_degree == 0:\n",
    "                return XP\n",
    "\n",
    "            # degree 1 term\n",
    "            XP[:, current_col : current_col + n_features] = X\n",
    "            index = list(range(current_col, current_col + n_features))\n",
    "            current_col += n_features\n",
    "            index.append(current_col)\n",
    "\n",
    "            # loop over degree >= 2 terms\n",
    "            for _ in range(2, self._max_degree + 1):\n",
    "                new_index = []\n",
    "                end = index[-1]\n",
    "                for feature_idx in range(n_features):\n",
    "                    start = index[feature_idx]\n",
    "                    new_index.append(current_col)\n",
    "                    if self.interaction_only:\n",
    "                        start += index[feature_idx + 1] - index[feature_idx]\n",
    "                    next_col = current_col + end - start\n",
    "                    if next_col <= current_col:\n",
    "                        break\n",
    "                    # XP[:, start:end] are terms of degree d - 1\n",
    "                    # that exclude feature #feature_idx.\n",
    "                    np.multiply(\n",
    "                        XP[:, start:end],\n",
    "                        X[:, feature_idx : feature_idx + 1],\n",
    "                        out=XP[:, current_col:next_col],\n",
    "                        casting=\"no\",\n",
    "                    )\n",
    "                    current_col = next_col\n",
    "\n",
    "                new_index.append(current_col)\n",
    "                index = new_index\n",
    "\n",
    "            if self._min_degree > 1:\n",
    "                n_XP, n_Xout = self._n_out_full, self.n_output_features_\n",
    "                if self.include_bias:\n",
    "                    Xout = jnp.empty(\n",
    "                        shape=(n_samples, n_Xout), dtype=XP.dtype, order=self.order\n",
    "                    )\n",
    "                    Xout[:, 0] = 1\n",
    "                    Xout[:, 1:] = XP[:, n_XP - n_Xout + 1 :]\n",
    "                else:\n",
    "                    Xout = XP[:, n_XP - n_Xout :].copy()\n",
    "                XP = Xout\n",
    "        return XP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  2.,  3.,  6.],\n",
       "       [ 1.,  4.,  5., 20.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XD = np.arange(6).reshape(3, 2)\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(XD)\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "poly.fit_transform(XD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "XP1 = transform(poly,XD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  2.,  3.,  6.],\n",
       "       [ 1.,  4.,  5., 20.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  2.,  3.,  6.],\n",
       "       [ 1.,  4.,  5., 20.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(6).reshape(3, 2)\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)\n",
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly._n_out_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly._min_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.interaction_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform3(self, X):\n",
    "    n_samples, n_features = X.shape\n",
    "    XP = jnp.empty(\n",
    "        shape=(n_samples, self._n_out_full), dtype=X.dtype\n",
    "    )\n",
    "    if self.include_bias:\n",
    "        XP = XP.at[:,0].set(1)\n",
    "        current_col = 1\n",
    "    else:\n",
    "        current_col = 0\n",
    "\n",
    "    if self._max_degree == 0:\n",
    "        return XP\n",
    "\n",
    "    XP = XP.at[:, current_col : current_col + n_features].set(X)\n",
    "    index = list(range(current_col, current_col + n_features))\n",
    "    current_col += n_features\n",
    "    index.append(current_col)\n",
    "\n",
    "    for _ in range(2, self._max_degree + 1):\n",
    "        new_index = []\n",
    "        end = index[-1]\n",
    "        for feature_idx in range(n_features):\n",
    "            start = index[feature_idx]\n",
    "            new_index.append(current_col)\n",
    "            if self.interaction_only:\n",
    "                start += index[feature_idx + 1] - index[feature_idx]\n",
    "            next_col = current_col + end - start\n",
    "            if next_col <= current_col:\n",
    "                break\n",
    "            XP = XP.at[:, current_col:next_col].set(jnp.multiply(\n",
    "                XP[:, start:end],\n",
    "                X[:, feature_idx : feature_idx + 1],\n",
    "            ))\n",
    "            current_col = next_col\n",
    "\n",
    "        new_index.append(current_col)\n",
    "        index = new_index\n",
    "    print(XP)\n",
    "    if self._min_degree > 1:\n",
    "        n_XP, n_Xout = self._n_out_full, self.n_output_features_\n",
    "        if self.include_bias:\n",
    "            Xout = jnp.empty(\n",
    "                shape=(n_samples, n_Xout), dtype=XP.dtype\n",
    "            )\n",
    "            Xout = Xout.at[:,0].set(1)\n",
    "            #Xout[:, 0] = 1\n",
    "            Xout = Xout.at[:, 1:].set(XP[:, n_XP - n_Xout + 1 :])\n",
    "            #Xout[:, 1:] = XP[:, n_XP - n_Xout + 1 :]\n",
    "        else:\n",
    "            Xout = XP[:, n_XP - n_Xout :].copy()\n",
    "        print(Xout)\n",
    "        XP = Xout.copy()\n",
    "    return XP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/auratrik/Anaconda33/envs/igwn-py39-lw/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:1939: UserWarning: Explicitly requested dtype int64 requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  lax_internal._check_user_dtype_supported(dtype, \"zeros\")\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  1  0]\n",
      " [ 1  2  3  6]\n",
      " [ 1  4  5 20]]\n"
     ]
    }
   ],
   "source": [
    "XP = transform3(poly, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 1,  0,  1,  0],\n",
       "             [ 1,  2,  3,  6],\n",
       "             [ 1,  4,  5, 20]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python igwn",
   "language": "python",
   "name": "igwn-py39-lw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
